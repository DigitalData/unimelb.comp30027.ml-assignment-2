{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Sample pipeline for text feature extraction and evaluation\n",
        "\n",
        "The dataset used in this example is the 20 newsgroups dataset which will be\n",
        "automatically downloaded and then cached and reused for the document\n",
        "classification example.\n",
        "\n",
        "You can adjust the number of categories by giving their names to the dataset\n",
        "loader or setting them to None to get the 20 of them.\n",
        "\n",
        "Here is a sample output of a run on a quad-core machine::\n",
        "\n",
        "  Loading 20 newsgroups dataset for categories:\n",
        "  ['alt.atheism', 'talk.religion.misc']\n",
        "  1427 documents\n",
        "  2 categories\n",
        "\n",
        "  Performing grid search...\n",
        "  pipeline: ['vect', 'tfidf', 'clf']\n",
        "  parameters:\n",
        "  {'clf__alpha': (1.0000000000000001e-05, 9.9999999999999995e-07),\n",
        "   'clf__max_iter': (10, 50, 80),\n",
        "   'clf__penalty': ('l2', 'elasticnet'),\n",
        "   'tfidf__use_idf': (True, False),\n",
        "   'vect__max_n': (1, 2),\n",
        "   'vect__max_df': (0.5, 0.75, 1.0),\n",
        "   'vect__max_features': (None, 5000, 10000, 50000)}\n",
        "  done in 1737.030s\n",
        "\n",
        "  Best score: 0.940\n",
        "  Best parameters set:\n",
        "      clf__alpha: 9.9999999999999995e-07\n",
        "      clf__max_iter: 50\n",
        "      clf__penalty: 'elasticnet'\n",
        "      tfidf__use_idf: True\n",
        "      vect__max_n: 2\n",
        "      vect__max_df: 0.75\n",
        "      vect__max_features: 50000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://stackoverflow.com/questions/50285973/pipeline-multiple-classifiers\n",
        "from sklearn.base import BaseEstimator\n",
        "class ClfSwitcher(BaseEstimator):\n",
        "\n",
        "    def __init__(\n",
        "        self, \n",
        "        estimator = SGDClassifier(),\n",
        "    ):\n",
        "        \"\"\"\n",
        "        A Custom BaseEstimator that can switch between classifiers.\n",
        "        :param estimator: sklearn object - The classifier\n",
        "        \"\"\" \n",
        "\n",
        "        self.estimator = estimator\n",
        "\n",
        "\n",
        "    def fit(self, X, y=None, **kwargs):\n",
        "        self.estimator.fit(X, y)\n",
        "        return self\n",
        "\n",
        "\n",
        "    def predict(self, X, y=None):\n",
        "        return self.estimator.predict(X)\n",
        "\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        return self.estimator.predict_proba(X)\n",
        "\n",
        "\n",
        "    def score(self, X, y):\n",
        "        return self.estimator.score(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Categories:\n",
            "{'positive', 'neutral', 'negative'}\n",
            "<class 'numpy.ndarray'>\n",
            "21802 documents\n",
            "3 categories\n",
            "\n",
            "Performing grid search...\n",
            "pipeline: ['vect', 'tfidf', 'clf']\n",
            "parameters:\n",
            "[{'clf__estimator': [SGDClassifier()],\n",
            "  'clf__estimator__alpha': (1e-05, 1e-06),\n",
            "  'clf__estimator__max_iter': (20,),\n",
            "  'clf__estimator__penalty': ('l2', 'elasticnet'),\n",
            "  'vect__max_df': (0.5, 0.75, 1.0),\n",
            "  'vect__ngram_range': ((1, 1), (1, 2), (1, 3))},\n",
            " {'clf__estimator': [GaussianNB()],\n",
            "  'clf__estimator__alpha': (1e-05, 1e-06),\n",
            "  'vect__max_df': (0.5, 0.75, 1.0),\n",
            "  'vect__ngram_range': ((1, 1), (1, 2), (1, 3))},\n",
            " {'clf__estimator': [MultinomialNB()],\n",
            "  'clf__estimator__alpha': (1e-05, 1e-06),\n",
            "  'vect__max_df': (0.5, 0.75, 1.0),\n",
            "  'vect__ngram_range': ((1, 1), (1, 2), (1, 3))},\n",
            " {'clf__estimator': [BernoulliNB()],\n",
            "  'clf__estimator__alpha': (1e-05, 1e-06),\n",
            "  'vect__max_df': (0.5, 0.75, 1.0),\n",
            "  'vect__ngram_range': ((1, 1), (1, 2), (1, 3))}]\n",
            "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
          ]
        }
      ],
      "source": [
        "# Author: Olivier Grisel <olivier.grisel@ensta.org>\n",
        "#         Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
        "#         Mathieu Blondel <mathieu@mblondel.org>\n",
        "# License: BSD 3 clause\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "from time import time\n",
        "import logging\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "# https://stackoverflow.com/questions/20186344/importing-an-ipynb-file-from-another-ipynb-file\n",
        "from ipynb.fs.full.feature_analysis import *\n",
        "\n",
        "# Display progress logs on stdout\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\")\n",
        "\n",
        "train_data = pd.read_csv(\"../datasets/Train.csv\", sep=',')\n",
        "train_tweets = train_data[['text']].values[:, 0]\n",
        "train_sentiments = train_data[['sentiment']].values[:, 0]\n",
        "test_data = pd.read_csv(\"../datasets/Test.csv\", sep=',')\n",
        "\n",
        "# #############################################################################\n",
        "# Load some categories from the training set\n",
        "categories = train_sentiments\n",
        "\n",
        "print(\"Categories:\")\n",
        "print(set(categories))\n",
        "\n",
        "# data = fetch_20newsgroups(subset=\"train\", categories=categories)\n",
        "data = train_tweets\n",
        "print(type(data))\n",
        "print(\"%d documents\" % len(data))\n",
        "print(\"%d categories\" % len(set(categories)))\n",
        "print()\n",
        "\n",
        "# #############################################################################\n",
        "# Define a pipeline combining a text feature extractor with a simple\n",
        "# classifier\n",
        "pipeline = Pipeline(\n",
        "    [\n",
        "        (\"vect\", CountVectorizer()),\n",
        "        (\"tfidf\", TfidfTransformer()),\n",
        "        (\"clf\", ClfSwitcher()),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# uncommenting more parameters will give better exploring power but will\n",
        "# increase processing time in a combinatorial way\n",
        "parameters = [\n",
        "    {\n",
        "        \"vect__max_df\": (0.5, 0.75, 1.0),\n",
        "        \"vect__ngram_range\": ((1, 1), (1, 2), (1, 3)),  # unigrams or bigrams\n",
        "        \"clf__estimator\": [SGDClassifier()],\n",
        "        \"clf__estimator__max_iter\": (20,),\n",
        "        \"clf__estimator__alpha\": (0.00001, 0.000001),\n",
        "        \"clf__estimator__penalty\": (\"l2\", \"elasticnet\"),\n",
        "    },\n",
        "    {\n",
        "        \"vect__max_df\": (0.5, 0.75, 1.0),\n",
        "        \"vect__ngram_range\": ((1, 1), (1, 2), (1, 3)),  # unigrams or bigrams\n",
        "        'clf__estimator': [GaussianNB()],\n",
        "        \"clf__estimator__alpha\": (0.00001, 0.000001),\n",
        "    },\n",
        "    {\n",
        "        \"vect__max_df\": (0.5, 0.75, 1.0),\n",
        "        \"vect__ngram_range\": ((1, 1), (1, 2), (1, 3)),  # unigrams or bigrams\n",
        "        'clf__estimator': [MultinomialNB()],\n",
        "        \"clf__estimator__alpha\": (0.00001, 0.000001),\n",
        "    },\n",
        "    {\n",
        "        \"vect__max_df\": (0.5, 0.75, 1.0),\n",
        "        \"vect__ngram_range\": ((1, 1), (1, 2), (1, 3)),  # unigrams or bigrams\n",
        "        'clf__estimator': [BernoulliNB()],\n",
        "        \"clf__estimator__alpha\": (0.00001, 0.000001),\n",
        "    },\n",
        "]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # multiprocessing requires the fork to happen in a __main__ protected\n",
        "    # block\n",
        "\n",
        "    # find the best parameters for both the feature extraction and the\n",
        "    # classifier\n",
        "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
        "\n",
        "    print(\"Performing grid search...\")\n",
        "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
        "    print(\"parameters:\")\n",
        "    pprint(parameters)\n",
        "    t0 = time()\n",
        "    grid_search.fit(data, categories)\n",
        "    print(\"done in %0.3fs\" % (time() - t0))\n",
        "    print()\n",
        "\n",
        "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
        "    print(\"Best parameters set:\")\n",
        "    best_parameters = grid_search.best_estimator_.get_params()\n",
        "    pprint(best_parameters)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
